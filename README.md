# ViTCM-LLM: Anonymous 2025 BIBM Submission Project

ğŸŒOfficial code implementation of "*ViTCM-LLM: A Multimodal RAG Framework for Advanced TCM Clinical Decision Support*"

![ViTCM-LLM Framework](img/ViTCM-LLM-framework-1.png)

## News

- **[2025.10.05]** ğŸ‰ Our paper "ViTCM-LLM: A Multimodal RAG Framework for Advanced TCM Clinical Decision Support" has been **accepted as a short paper** at **IEEE BIBM 2025** (IEEE International Conference on Bioinformatics and Biomedicine 2025). The conference received 2083 submissions with an acceptance rate of 19.8% (411 short papers accepted).

- **[2025.07.29]** ğŸ¤— We release ViTCM-LLM, a multimodal RAG framework for advanced TCM clinical decision support. All model code, training code, and evaluation code are anonymously open-sourced. Please check the document below for more details. Welcome to **watch** ğŸ‘€ this repository for the latest updates.

## ğŸ“ Project Structure

```
TCMPipe/
â”œâ”€â”€ codes/
â”‚   â”œâ”€â”€ requirements.txt              # Unified dependencies for entire project
â”‚   â”‚
â”‚   â”œâ”€â”€ Prescription code/           # RAG-based prescription analysis
â”‚   â”‚   â”œâ”€â”€ tcm_rag_processor.py    # Main RAG processing system
â”‚   â”‚   â”œâ”€â”€ tcm_rag_diagnosis.py    # Standalone diagnosis system
â”‚   â”‚   â”œâ”€â”€ tcm_json_processor.py   # JSON data processing
â”‚   â”‚   â”œâ”€â”€ run_rag_seed42.py       # RAG execution with seed
â”‚   â”‚   â”œâ”€â”€ faiss_index/            # Vector database (auto-generated)
â”‚   â”‚   â””â”€â”€ README_CN.md            # Chinese documentation
â”‚   â”‚
â”‚   â””â”€â”€ TONGUE_diagnosis/           # Tongue diagnosis system
â”‚       â”œâ”€â”€ preprocess/             # Data preprocessing
â”‚       â”‚   â”œâ”€â”€ augment_tongue_dataset.py           # Image augmentation
â”‚       â”‚   â”œâ”€â”€ rename_files.py                     # File renaming utilities
â”‚       â”‚   â”œâ”€â”€ test_augmentation.py                # Augmentation testing
â”‚       â”‚   â”œâ”€â”€ convert_to_sharegpt_vllm_json_split.py # Split conversion
â”‚       â”‚   â”œâ”€â”€ verify_matching.py                  # Data matching verification
â”‚       â”‚   â”œâ”€â”€ split_and_convert_to_sharegpt_vllm.py  # Data splitting
â”‚       â”‚   â””â”€â”€ split_and_convert_to_qwen25vl_jsonl.py # Qwen2.5-VL format
â”‚       â”‚
â”‚       â”œâ”€â”€ process/                # Model processing
â”‚       â”‚   â”œâ”€â”€ process_qwen2_5vl_infer.py         # Qwen2.5-VL inference
â”‚       â”‚   â”œâ”€â”€ process_gemini.py                  # Gemini processing
â”‚       â”‚   â”œâ”€â”€ process_gpt_o3.py                  # GPT-4o processing
â”‚       â”‚   â”œâ”€â”€ process_llama4_groq.py             # Llama4-Groq processing
â”‚       â”‚   â”œâ”€â”€ process_grok.py                    # Grok processing
â”‚       â”‚   â”œâ”€â”€ process_llama4_scout.py            # Llama4-Scout processing
â”‚       â”‚   â””â”€â”€ process_grok_label_eval.py         # Grok label evaluation
â”‚       â”‚
â”‚       â””â”€â”€ evalutation/            # Evaluation framework
â”‚           â”œâ”€â”€ evaluation2_ver2.py                # Main evaluation system
â”‚           â”œâ”€â”€ calculate_bleu_score.py            # BLEU score calculation
â”‚           â”œâ”€â”€ generate_combined_results.py       # Result combination
â”‚           â”œâ”€â”€ debug_full_dataset.py              # Dataset debugging
â”‚           â”œâ”€â”€ process_qwen2_5vl_label_eval.py   # Qwen2.5-VL evaluation
â”‚           â”œâ”€â”€ process_llama4groq_label_eval.py  # Llama4-Groq evaluation
â”‚           â””â”€â”€ token_config.json                 # Token configuration
```

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install unified dependencies
cd codes
pip install -r requirements.txt

# Install Ollama and download model
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull qwen3:8b
```

### 1. Prescription Analysis (RAG System)

#### Setup
```bash
cd codes/Prescription\ code/

# Ensure Ollama service is running
ollama serve
```

#### Usage
```python
from tcm_rag_diagnosis import TCMRAGDiagnosis

# Initialize the diagnosis system
diagnosis_system = TCMRAGDiagnosis(
    knowledge_base_dir="./knowledge_base",
    embedding_model_name="BAAI/bge-small-zh-v1.5",
    llm_model_name="qwen3:8b"
)

# Initialize the system
diagnosis_system.initialize_system()

# Prepare patient data
patient_data = {
    "CaseID": "case_001",
    "shezhen": "èˆŒçº¢è‹”é»„",      # Tongue diagnosis
    "maizhen": "è„‰æ•°æœ‰åŠ›",      # Pulse diagnosis
    "zhusu": "å’³å—½ç—°é»„3å¤©",     # Chief complaint
    "xianbingshi": "æ‚£è€…3å¤©å‰å—é£å¯’åå‡ºç°å’³å—½ï¼Œç—°é»„ç²˜ç¨ ï¼Œä¼´æœ‰å‘çƒ­"  # Present illness
}

# Perform diagnosis
result = diagnosis_system.diagnose(patient_data)
diagnosis_system.print_diagnosis_summary(result)
```

#### Output Format
```json
{
    "CaseID": "case_001",
    "structured_result": {
        "zhenduan": "å’³å—½ç—…",
        "bianzheng": "é£çƒ­çŠ¯è‚º",
        "chufang": "æ¡‘èŠé¥®åŠ å‡",
        "zhenduan_liyou": "æ‚£è€…å’³å—½ç—°é»„ï¼ŒèˆŒçº¢è‹”é»„ï¼Œè„‰æ•°æœ‰åŠ›ï¼Œä¸ºé£çƒ­çŠ¯è‚ºä¹‹è±¡..."
    }
}
```

### 2. Tongue Diagnosis System

#### Data Preprocessing
```bash
cd codes/TONGUE_diagnosis/preprocess/

# Check for corrupted images
python check_corrupted_images.py --image_dir /path/to/images --json_file data.json

# Augment tongue images
python augment_tongue_dataset.py --input data.json --output augmented_data.json

# Convert to ShareGPT format
python convert_to_sharegpt_vllm_json.py --input data.json --output sharegpt_data.json

# Rename files (replace spaces with underscores)
python rename_files.py --directory /path/to/images
```

#### Model Processing
```bash
cd codes/TONGUE_diagnosis/process/

# Process with Qwen2.5-VL
python process_qwen2_5vl_infer.py \
    --input input.jsonl \
    --output output.jsonl \
    --max_new_tokens 128 \
    --flash_attention

# Process with Gemini
python process_gemini.py

```

#### Evaluation
```bash
cd codes/TONGUE_diagnosis/evalutation/

# Run evaluation
python evaluation2_ver2.py \
    --input predictions.jsonl \
    --output results.txt \
    --config token_config.json \
    --mode category

# Calculate BLEU scores
python calculate_bleu_score.py
```

## ğŸ”§ Key Features

### Prescription Analysis (RAG System)

- **Knowledge-Based Diagnosis**: Uses large-scale TCM knowledge base
- **Multi-Modal Input**: Supports tongue diagnosis, pulse diagnosis, and symptoms
- **Structured Output**: Automatically extracts diagnosis, syndrome differentiation, and prescription
- **Batch Processing**: Supports single case and batch diagnosis
- **Incremental Processing**: Supports interruption recovery and incremental saving

### Tongue Diagnosis System

- **Image Augmentation**: Comprehensive data augmentation for tongue images
- **Multi-Model Support**: Supports various vision-language models (Qwen2.5-VL, Gemini, GPT-4o, Llama4, Grok)
- **Standardized Evaluation**: Production-ready evaluation metrics
- **Token-Based Analysis**: Sophisticated token extraction and matching
- **Data Preprocessing**: Extensive preprocessing pipeline for image and data validation

## ğŸ“Š Evaluation Metrics

### Prescription Analysis
- **Diagnosis Accuracy**: Measures correct disease identification
- **Syndrome Differentiation**: Evaluates pattern recognition accuracy
- **Prescription Completeness**: Checks for complete prescription information

### Tongue Diagnosis

- **Category-Level Metrics**: Separate evaluation for tongue, coat, location, and other categories
- **Similarity Scoring**: Hungarian algorithm for optimal token matching
- **BLEU Score**: Character-level BLEU score calculation

## ğŸ› ï¸ Configuration

### RAG System Configuration
```python
# Model parameters
embedding_model_name = "BAAI/bge-small-zh-v1.5"  # Embedding model
llm_model_name = "qwen3:8b"                      # Language model
faiss_index_path = "./faiss_index"               # Vector index path

# Processing parameters
chunk_size = 1000                                # Document chunk size
chunk_overlap = 100                              # Chunk overlap
temperature = 0.7                                # Generation temperature
top_p = 0.9                                      # Nucleus sampling
top_k = 50                                       # Top-k sampling
```

### Tongue Diagnosis Configuration
```json
{
    "category_map": {
        "tongue": "tongue",
        "coat": "coat", 
        "location": "location"
    },
    "weights": {
        "tongue": 2.0,
        "coat": 1.5,
        "location": 1.0,
        "other": 1.0
    },
    "token_dicts": {
        "tongue": ["red", "pale", "purple", "dark"],
        "coat": ["white", "yellow", "gray", "black"]
    }
}
```

## ğŸ” Troubleshooting

### Common Issues

1. **Ollama Connection Error**
   ```bash
   # Check Ollama service
   ollama serve
   
   # Verify model installation
   ollama list
   ```

2. **Memory Issues**
   ```bash
   # Reduce chunk size
   chunk_size = 500
   
   # Use smaller embedding model
   embedding_model_name = "BAAI/bge-small-en-v1.5"
   ```

3. **Model Loading Errors**
   ```bash
   # Install flash attention for better performance
   pip install flash-attn --no-build-isolation
   ```

4. **Image Processing Issues**
   ```bash
   # Check for corrupted images
   python check_corrupted_images.py --image_dir /path/to/images
   
   # Validate image matching
   python check_image_matching.py --image_dir /path/to/images --json_file data.json
   ```
## ğŸ“š Dataset

The dataset will be updated soon

**Note**: This system is designed for research and educational purposes. For clinical use, please consult with qualified TCM practitioners and follow appropriate medical guidelines.

<!-- ## ğŸ“„ Citation

If you use this code in your research, please cite our paper:

```bibtex
@inproceedings{vitcm-llm-2025,
    title={ViTCM-LLM: A Multimodal RAG Framework for Advanced TCM Clinical Decision Support},
    author={Luo, Lihui and Chae, Joongwon and Liu, Yang and Pantic, Igor and Devedzic, Vladan and Sun, Zhumei and Zeng, Zelin and Matlatipov, Sanatbek and Yin, Xiaoming and Qin, Peiwu},
    booktitle={IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
    year={2025},
    note={Accepted as short paper}
}
``` -->

## ğŸ“„ License

This project is licensed under the Apache License 2.0 - see the LICENSE file for details.

## ğŸ”— Related Links

* **GitHub Repository**: [https://github.com/jw-chae/ViTCM_LLM](https://github.com/jw-chae/ViTCM_LLM)
* **Conference Website**: [https://ieeebibm.org/BIBM2025/](https://ieeebibm.org/BIBM2025/)

## ğŸ™ Acknowledgments

We would like to thank all reviewers and the IEEE BIBM 2025 Program Committee for their valuable feedback. 